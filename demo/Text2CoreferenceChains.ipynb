{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7aa55b9d3c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtext2corefchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mudpipe_spacy_lang_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmentions2chains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mudpipe_spacy_lang_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Models/french-ud-2.0-170801.udpipe'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"fr_core_news_md\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/French-CRS/french-crs/text2corefchains.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mufal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudpipe\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInputFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessingError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from text2corefchains import udpipe_spacy_lang_model, mentions2chains\n",
    "model=udpipe_spacy_lang_model('./Models/french-ud-2.0-170801.udpipe',\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/mehdi.mirzapour/French-CRS/demo',\n",
       " '/anaconda3/envs/French-CRS/lib/python37.zip',\n",
       " '/anaconda3/envs/French-CRS/lib/python3.7',\n",
       " '/anaconda3/envs/French-CRS/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/mehdi.mirzapour/.local/lib/python3.7/site-packages',\n",
       " '/anaconda3/envs/French-CRS/lib/python3.7/site-packages',\n",
       " '/anaconda3/envs/French-CRS/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/mehdi.mirzapour/.ipython',\n",
       " '../french-crs']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append('../french-crs')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tokenize(\"à mettre en œuvre de le protectionnisme intelligent à mettre en avant de le patriotisme économique pour donner un avantage à les entreprises françaises dans la commande publique voilà tout cela . Le patriotisme économique qui n ’ a jamais été mis en œuvre le protectionnisme intelligent la défiscalisation de les heures supplémentaires la suppression de le travail détaché la baisse de les charges mais exclusivement pour les TPE PME . Il met en place un patriotisme économique un protectionnisme intelligent il dit à les constructeurs américains si vous voulez aller faire vos voitures à l ’ étranger construire une voiture à l’ étranger alors vous paierez une taxe en les réimportant à les Etats-Unis . D ’ autant que évidemment ce que fait Trump m ’ intéresse et pour cause puisqu ’ il met en place la politique que j’ appelle de mes vœux depuis très longtemps et notamment la politique de patriotisme économique de protectionnisme intelligent\")    \n",
    "model.parse_sentences_json()\n",
    "model.update_json_sents_with_spacy_entities(operation=\"in\")\n",
    "model.update_json_sents_with_mentions(operation=\"==\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs & Features Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_generator=mentions2chains(model.mentions_ids_in_json_sents)\n",
    "chains_generator.generate_mention_pairs(window_size=30, iteration=3)\n",
    "chains_generator.generate_json_mention_pairs(model.mentions_ids_in_json_sents,model.sentences_json)\n",
    "chains_generator.json_mention_pairs2dataframe(save_file=True, file_path=\"./unseen_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# model = joblib.load(\"./Optimized_Models/Model_ANCOR_Ballanced_Full.model\")\n",
    "# list(chains_generator.model_input_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_generator.json_mention_pairs2dataframe(save_file=True, file_path=\"./unseen_data.xlsx\")\n",
    "chains_generator.init_data_model(model_name=\"./Optimized_Models/Model_ANCOR_Representative_INDIRECTE.model\", \n",
    "                                 input_method=\".xlsx\",\n",
    "                                 file_path=\"./unseen_data.xlsx\",\n",
    "                                 column_outcome=\"Prediction\",\n",
    "                                 threshold=0.5)\n",
    "\n",
    "chains_generator.apply_model_to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Chains Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pairs2chains import chains_builder\n",
    "\n",
    "chains = chains_builder(\"./unseen_data.xlsx\",\n",
    "                        \"./unseen_data.xlsx\",\n",
    "                        \"Prediction\",\n",
    "                        \"Prediction\",\n",
    "                        0.5)\n",
    "\n",
    "chains.generate_gold_model_json_output(mode=\"test\")\n",
    "chains.coref_chains_pred_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coreference Chains Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains.context_visualizer(model.sentences_json,\n",
    "                          context_left_window=3,\n",
    "                          context_right_window=3,\n",
    "                          theme_left_window=5,\n",
    "                          theme_right_window=4,\n",
    "                          file_path=\"context_visualized.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment I : Running through 12 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pairs2chains import chains_builder\n",
    "threshold=0.5\n",
    "\n",
    "\n",
    "PATH=\"./Optimized_Models/\"\n",
    "\n",
    "\n",
    "# Uncomment for automatic files_list instead of manually creation of list\n",
    "\n",
    "# files_list=[file[file.rfind(\"/\")+1:] for file in glob.glob(PATH+\"*.model\")]\n",
    "\n",
    "\n",
    "files_list=[\n",
    "#             'Model_ANCOR_Ballanced_Full.model',\n",
    "#             'Model_ANCOR_Ballanced_ANAPHORE.model',\n",
    "#             'Model_ANCOR_Ballanced_DIRECTE.model',\n",
    "            'Model_ANCOR_Ballanced_INDIRECTE.model',\n",
    "#             'Model_ANCOR_Representative_Full.model',\n",
    "#             'Model_ANCOR_Representative_ANAPHORE.model',\n",
    "#             'Model_ANCOR_Representative_DIRECTE.model',\n",
    "            'Model_ANCOR_Representative_INDIRECTE.model'\n",
    "#             'Model_ANCOR_Window_Full.model',\n",
    "#             'Model_ANCOR_Window_ANAPHORE.model',\n",
    "#             'Model_ANCOR_Window_DIRECTE.model',\n",
    "#             'Model_ANCOR_Window_INDIRECTE.model'\n",
    "]\n",
    "\n",
    "\n",
    "for file in files_list:\n",
    "    \n",
    "    chains_generator=mentions2chains(model.mentions_ids_in_json_sents)\n",
    "    chains_generator.generate_mention_pairs(window_size=30, iteration=3)\n",
    "    chains_generator.generate_json_mention_pairs(model.mentions_ids_in_json_sents,model.sentences_json)\n",
    "    chains_generator.json_mention_pairs2dataframe(save_file=True, file_path=\"./unseen_data.xlsx\")\n",
    "    \n",
    "    chains_generator.init_data_model(model_name=\"./Optimized_Models/\"+file, \n",
    "                                 input_method=\".xlsx\",\n",
    "                                 file_path=\"./unseen_data.xlsx\",\n",
    "                                 column_outcome=\"Prediction\",\n",
    "                                 threshold=threshold)\n",
    "\n",
    "    chains_generator.apply_model_to_dataset()\n",
    "    \n",
    "    from pairs2chains import chains_builder\n",
    "\n",
    "    chains = chains_builder(\"./unseen_data.xlsx\",\n",
    "                            \"./unseen_data.xlsx\",\n",
    "                            \"Prediction\",\n",
    "                            \"Prediction\",\n",
    "                            0.5)\n",
    "\n",
    "    chains.generate_gold_model_json_output(mode=\"test\")\n",
    "    \n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"Model: \"+file)\n",
    "    for chain in chains.coref_chains_pred_json:\n",
    "        print(chain)\n",
    "        print(chains.coref_chains_pred_json[chain])\n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment II : Running through different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pairs2chains import chains_builder\n",
    "threshold=1.05\n",
    "\n",
    "for iterate in range(0,20):\n",
    "    threshold-=0.05\n",
    "    chains = chains_builder(\"./unseen_data.xlsx\",\n",
    "                            \"./unseen_data.xlsx\",\n",
    "                            \"Prediction\",\n",
    "                            \"Prediction\",\n",
    "                            threshold)\n",
    "    coreference_chain_built=chains.generate_coreference_chains(chains.gold_dataframe, \n",
    "                                                               chains.gold_column, \n",
    "                                                               mode=\"test\")\n",
    "    \n",
    "    print(\"---------------------------------------------------------------\")\n",
    "    print(\"Threshold :\"+str(round(threshold,2)))\n",
    "    for chain in coreference_chain_built:\n",
    "        print(chain)\n",
    "        print(coreference_chain_built[chain])\n",
    "    print(\"---------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
